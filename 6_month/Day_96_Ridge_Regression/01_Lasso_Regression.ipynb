{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64f62d4",
   "metadata": {},
   "source": [
    "# Lasso Regression `Start`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "12a7212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.11867641198721099\n",
      "Mean Squared Error: 5.344222169060111\n",
      "Mean Squared Error: 72.66217710608291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generate synthetic regression data\n",
    "X, y = make_regression(n_samples=100, n_features=20, noise=0.1, random_state=42)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Create a Lasso regression model\n",
    "model = Lasso(alpha=0.1)\n",
    "model_ridge = Ridge(alpha=1.0)\n",
    "model_elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "model_elastic.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_ridge = model_ridge.predict(X_test)\n",
    "y_pred_elastic = model_elastic.predict(X_test)\n",
    "# Evaluate the model using Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "mse_elastic = mean_squared_error(y_test, y_pred_elastic)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Squared Error:\", mse_ridge)\n",
    "print(\"Mean Squared Error:\", mse_elastic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "af21dab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Lasso regression: 0.1\n",
      "Best alpha for Ridge regression: 0.1\n",
      "Best alpha for ElasticNet regression: 0.1\n",
      "Best score for Lasso regression: 0.99999050391632\n",
      "Best score for Ridge regression: 0.9999940808033255\n",
      "Best score for ElasticNet regression: 0.9996913195589207\n",
      "Mean Squared Error for Lasso Regression: 0.11867641198721099\n",
      "Mean Squared Error for Ridge Regression: 0.07413054644463885\n",
      "Mean Squared Error for ElasticNet Regression: 3.708762287828274\n"
     ]
    }
   ],
   "source": [
    "# Fine tune the hyperparameters using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the parameter grid for Lasso regression\n",
    "param_grid_lasso = {'alpha': [0.1, 10, 0.1]}\n",
    "# Define the parameter grid for Ridge regression\n",
    "param_grid_ridge = {'alpha': [0.1, 10, 0.1]}\n",
    "# Define the parameter grid for ElasticNet regression    \n",
    "param_grid_elastic = {'alpha': [ 0.1, 10, 0.1], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "# Create GridSearchCV for Lasso regression\n",
    "grid_search_lasso = GridSearchCV(estimator=Lasso(), param_grid=param_grid_lasso, cv=10)\n",
    "# Create GridSearchCV for Ridge regression\n",
    "grid_search_ridge = GridSearchCV(estimator=Ridge(), param_grid=param_grid_ridge, cv=10)\n",
    "# Create GridSearchCV for ElasticNet regression    \n",
    "grid_search_elastic = GridSearchCV(estimator=ElasticNet(), param_grid=param_grid_elastic, cv=10)\n",
    "# Fit the GridSearchCV models to the training data\n",
    "grid_search_lasso.fit(X_train, y_train)\n",
    "grid_search_ridge.fit(X_train, y_train)\n",
    "grid_search_elastic.fit(X_train, y_train)\n",
    "# Get the best hyperparameters for Lasso regression\n",
    "best_alpha_lasso = grid_search_lasso.best_params_['alpha']\n",
    "# Get the best hyperparameters for Ridge regression\n",
    "best_alpha_ridge = grid_search_ridge.best_params_['alpha']\n",
    "# Get the best hyperparameters for ElasticNet regression    \n",
    "best_alpha_elastic = grid_search_elastic.best_params_['alpha']\n",
    "# Create a new Lasso regression model with the best hyperparameters\n",
    "model_lasso = Lasso(alpha=best_alpha_lasso) \n",
    "# Create a new Ridge regression model with the best hyperparameters\n",
    "model_ridge = Ridge(alpha=best_alpha_ridge)\n",
    "# print the best hyperparameters\n",
    "print(\"Best alpha for Lasso regression:\", best_alpha_lasso)\n",
    "print(\"Best alpha for Ridge regression:\", best_alpha_ridge)\n",
    "print(\"Best alpha for ElasticNet regression:\", best_alpha_elastic)\n",
    "# print the best score\n",
    "print(\"Best score for Lasso regression:\", grid_search_lasso.best_score_)\n",
    "print(\"Best score for Ridge regression:\", grid_search_ridge.best_score_)\n",
    "print(\"Best score for ElasticNet regression:\", grid_search_elastic.best_score_)\n",
    "#Create a new ElasticNet regression model with the best hyperparameters    \n",
    "# Fit the models to the training data\n",
    "model_lasso.fit(X_train, y_train)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "model_elastic.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred_lasso = model_lasso.predict(X_test)\n",
    "y_pred_ridge = model_ridge.predict(X_test)    \n",
    "y_pred_elastic = model_elastic.predict(X_test)\n",
    "# Evaluate the models using Mean Squared Error\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "mse_elastic = mean_squared_error(y_test, y_pred_elastic)\n",
    "print(\"Mean Squared Error for Lasso Regression:\", mse_lasso)\n",
    "print(\"Mean Squared Error for Ridge Regression:\", mse_ridge)    \n",
    "print(\"Mean Squared Error for ElasticNet Regression:\", mse_elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c472e77",
   "metadata": {},
   "source": [
    "# what is L1 and L2 regularization?\n",
    "L1 regularization, also known as Lasso regression, adds a penalty equal \n",
    "to the absolute value of the coefficients to the loss function. \n",
    "This can lead to sparse models where some coefficients are exactly zero, \n",
    "effectively performing feature selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
