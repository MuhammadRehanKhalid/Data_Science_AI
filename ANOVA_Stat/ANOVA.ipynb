{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b62e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "df_oneway = pd.DataFrame({\n",
    "    'factor': np.repeat(['A', 'B', 'C'], 10),\n",
    "    'response': np.random.normal(loc=10, scale=2, size=30)\n",
    "})\n",
    "df_oneway.to_excel(\"dummy_oneway.xlsx\", index=False)\n",
    "df_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-way ANOVA\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "df = df_oneway\n",
    "# Example: response ~ factor\n",
    "model = ols('response ~ C(factor)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "# display(anova_table)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a6f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract degrees of freedom and variance (MSE) from ANOVA table\n",
    "# Get degrees of freedom for error/residual\n",
    "df_error = anova_table.loc['Residual', 'df'] if 'Residual' in anova_table.index else anova_table.iloc[-1]['df']\n",
    "\n",
    "# Get Mean Square Error (MSE) for error/residual\n",
    "mse_error = anova_table.loc['Residual', 'sum_sq'] / anova_table.loc['Residual', 'df'] if 'Residual' in anova_table.index else anova_table.iloc[-1]['sum_sq'] / anova_table.iloc[-1]['df']\n",
    "\n",
    "print(f\"Degrees of Freedom (Error): {df_error}\")\n",
    "print(f\"Mean Square Error (MSE): {mse_error}\")\n",
    "\n",
    "# You can now use df_error and mse_error for LSD, Tukey HSD, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSD Value Calculation\n",
    "from scipy.stats import t\n",
    "\n",
    "# Suppose n = number of replicates per group, means = group means\n",
    "n = 10  # adjust as per your data\n",
    "alpha = 0.05\n",
    "t_critical = t.ppf(1 - alpha/2, df_error)\n",
    "lsd = t_critical * (2 * mse_error / n) ** 0.5\n",
    "print(f\"LSD value: {lsd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean comparison and significance letters using Tukey HSD\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "factor_col = 'factor'\n",
    "response_col = 'response'\n",
    "\n",
    "# 1. Calculate group means\n",
    "means = df.groupby(factor_col)[response_col].mean().reset_index()\n",
    "means.columns = [factor_col, 'Mean']\n",
    "\n",
    "# 2. Tukey HSD test\n",
    "mc = MultiComparison(df[response_col], df[factor_col])\n",
    "tukey_result = mc.tukeyhsd()\n",
    "\n",
    "# 3. Assign significance letters (robust version)\n",
    "import numpy as np\n",
    "\n",
    "def get_significance_letters(tukey_result, group_names):\n",
    "    n = len(group_names)\n",
    "    sig_matrix = np.ones((n, n), dtype=bool)\n",
    "    # Use tukey_result.summary() to get group pairs and reject status\n",
    "    summary = tukey_result.summary()\n",
    "    data = summary.data[1:]  # skip header\n",
    "    group_to_idx = {name: i for i, name in enumerate(group_names)}\n",
    "    for row in data:\n",
    "        g1, g2, _, _, _, _, reject = row\n",
    "        i, j = group_to_idx[g1], group_to_idx[g2]\n",
    "        sig_matrix[i, j] = not reject\n",
    "        sig_matrix[j, i] = not reject\n",
    "    # Assign letters\n",
    "    letters = [''] * n\n",
    "    current_letter = 'A'\n",
    "    assigned = [False] * n\n",
    "    for i in range(n):\n",
    "        if not assigned[i]:\n",
    "            letters[i] += current_letter\n",
    "            assigned[i] = True\n",
    "            for j in range(i+1, n):\n",
    "                if sig_matrix[i, j]:\n",
    "                    letters[j] += current_letter\n",
    "                    assigned[j] = True\n",
    "            current_letter = chr(ord(current_letter) + 1)\n",
    "    return dict(zip(group_names, letters))\n",
    "\n",
    "letters_dict = get_significance_letters(tukey_result, tukey_result.groupsunique)\n",
    "means['Letter'] = means[factor_col].map(letters_dict)\n",
    "\n",
    "# 4. Display the table\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a494c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "factor1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "factor2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "response",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "46f47d52-8145-4ea2-bb2b-b80d41b6102f",
       "rows": [
        [
         "0",
         "X",
         "M",
         "24.873036090989725"
        ],
        [
         "1",
         "X",
         "M",
         "18.164730759049775"
        ],
        [
         "2",
         "X",
         "M",
         "18.415484743209632"
        ],
        [
         "3",
         "X",
         "M",
         "16.78109413353149"
        ],
        [
         "4",
         "X",
         "M",
         "22.596222887974037"
        ],
        [
         "5",
         "X",
         "N",
         "13.095383909359152"
        ],
        [
         "6",
         "X",
         "N",
         "25.23443529264944"
        ],
        [
         "7",
         "X",
         "N",
         "17.716379297314692"
        ],
        [
         "8",
         "X",
         "N",
         "20.957117288171297"
        ],
        [
         "9",
         "X",
         "N",
         "19.25188887356777"
        ],
        [
         "10",
         "X",
         "O",
         "24.386323811134922"
        ],
        [
         "11",
         "X",
         "O",
         "13.819577871507038"
        ],
        [
         "12",
         "X",
         "O",
         "19.032748387959476"
        ],
        [
         "13",
         "X",
         "O",
         "18.847836935994753"
        ],
        [
         "14",
         "X",
         "O",
         "23.401308327006312"
        ],
        [
         "15",
         "Y",
         "M",
         "16.70032619805791"
        ],
        [
         "16",
         "Y",
         "M",
         "19.482715377348693"
        ],
        [
         "17",
         "Y",
         "M",
         "17.366424746235886"
        ],
        [
         "18",
         "Y",
         "M",
         "20.12664124014678"
        ],
        [
         "19",
         "Y",
         "M",
         "21.748445641147466"
        ],
        [
         "20",
         "Y",
         "N",
         "16.698142468361237"
        ],
        [
         "21",
         "Y",
         "N",
         "23.43417112951884"
        ],
        [
         "22",
         "Y",
         "N",
         "22.704772161778386"
        ],
        [
         "23",
         "Y",
         "N",
         "21.507483016705606"
        ],
        [
         "24",
         "Y",
         "N",
         "22.702567847793237"
        ],
        [
         "25",
         "Y",
         "O",
         "17.948816422477"
        ],
        [
         "26",
         "Y",
         "O",
         "19.631329323444056"
        ],
        [
         "27",
         "Y",
         "O",
         "17.192691697222795"
        ],
        [
         "28",
         "Y",
         "O",
         "19.19633576112195"
        ],
        [
         "29",
         "Y",
         "O",
         "21.591066400214558"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 30
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor1</th>\n",
       "      <th>factor2</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X</td>\n",
       "      <td>M</td>\n",
       "      <td>24.873036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X</td>\n",
       "      <td>M</td>\n",
       "      <td>18.164731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X</td>\n",
       "      <td>M</td>\n",
       "      <td>18.415485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X</td>\n",
       "      <td>M</td>\n",
       "      <td>16.781094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X</td>\n",
       "      <td>M</td>\n",
       "      <td>22.596223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>X</td>\n",
       "      <td>N</td>\n",
       "      <td>13.095384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>X</td>\n",
       "      <td>N</td>\n",
       "      <td>25.234435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>X</td>\n",
       "      <td>N</td>\n",
       "      <td>17.716379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>X</td>\n",
       "      <td>N</td>\n",
       "      <td>20.957117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>X</td>\n",
       "      <td>N</td>\n",
       "      <td>19.251889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>24.386324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>13.819578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>19.032748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>18.847837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>23.401308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>16.700326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>19.482715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>17.366425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>20.126641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>21.748446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>16.698142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>23.434171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>22.704772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>21.507483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>22.702568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Y</td>\n",
       "      <td>O</td>\n",
       "      <td>17.948816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Y</td>\n",
       "      <td>O</td>\n",
       "      <td>19.631329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Y</td>\n",
       "      <td>O</td>\n",
       "      <td>17.192692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Y</td>\n",
       "      <td>O</td>\n",
       "      <td>19.196336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Y</td>\n",
       "      <td>O</td>\n",
       "      <td>21.591066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor1 factor2   response\n",
       "0        X       M  24.873036\n",
       "1        X       M  18.164731\n",
       "2        X       M  18.415485\n",
       "3        X       M  16.781094\n",
       "4        X       M  22.596223\n",
       "5        X       N  13.095384\n",
       "6        X       N  25.234435\n",
       "7        X       N  17.716379\n",
       "8        X       N  20.957117\n",
       "9        X       N  19.251889\n",
       "10       X       O  24.386324\n",
       "11       X       O  13.819578\n",
       "12       X       O  19.032748\n",
       "13       X       O  18.847837\n",
       "14       X       O  23.401308\n",
       "15       Y       M  16.700326\n",
       "16       Y       M  19.482715\n",
       "17       Y       M  17.366425\n",
       "18       Y       M  20.126641\n",
       "19       Y       M  21.748446\n",
       "20       Y       N  16.698142\n",
       "21       Y       N  23.434171\n",
       "22       Y       N  22.704772\n",
       "23       Y       N  21.507483\n",
       "24       Y       N  22.702568\n",
       "25       Y       O  17.948816\n",
       "26       Y       O  19.631329\n",
       "27       Y       O  17.192692\n",
       "28       Y       O  19.196336\n",
       "29       Y       O  21.591066"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "df_twoway = pd.DataFrame({\n",
    "    'factor1': np.repeat(['X', 'Y'], 15),\n",
    "    'factor2': np.tile(np.repeat(['M', 'N', 'O'], 5), 2),\n",
    "    'response': np.random.normal(loc=20, scale=3, size=30)\n",
    "})\n",
    "df_twoway.to_excel(\"dummy_twoway.xlsx\", index=False)\n",
    "df_twoway.head()\n",
    "# df_twoway = pd.read_excel(\"D:\\\\Study\\\\Study and Extras\\\\Scientific Work\\\\Spinach Rehan\\\\Data Graphs\\\\Sheet1Tabl.xlsx\", sheet_name=\"Stat Sheet\")\n",
    "df_twoway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-way ANOVA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import t\n",
    "import re\n",
    "\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "def get_lsd_letters_cld(means_sorted, lsd):\n",
    "    group_names = means_sorted['group'].tolist()\n",
    "    means = means_sorted['Mean'].values\n",
    "    n = len(means)\n",
    "    letter_sets = [set() for _ in range(n)]\n",
    "    current_letter = ord('a')\n",
    "    for i in range(n):\n",
    "        used_letters = set()\n",
    "        for j in range(i):\n",
    "            if abs(means[i] - means[j]) > lsd:\n",
    "                used_letters |= letter_sets[j]\n",
    "        while chr(current_letter) in used_letters:\n",
    "            current_letter += 1\n",
    "        letter_sets[i].add(chr(current_letter))\n",
    "        for j in range(i+1, n):\n",
    "            if abs(means[i] - means[j]) <= lsd:\n",
    "                letter_sets[j].add(chr(current_letter))\n",
    "    letters = [''.join(sorted(s)) for s in letter_sets]\n",
    "    return dict(zip(group_names, letters))\n",
    "\n",
    "def safe_sheet_name(name, suffix=\"\"):\n",
    "    name = re.sub(r'[\\\\/*?:\\[\\]]', '_', str(name))\n",
    "    base = name[:25]\n",
    "    return f\"{base}{suffix}\"\n",
    "\n",
    "def two_way_anova(df, output_path):\n",
    "    factor_cols = df.columns[:2].tolist()\n",
    "    response_cols = df.columns[2:].tolist()\n",
    "    with pd.ExcelWriter(output_path) as writer:\n",
    "        for response in response_cols:\n",
    "            df_sub = df_twoway[factor_cols + [response]].dropna()\n",
    "            df_sub['group'] = df_sub[factor_cols].astype(str).apply(lambda row: '_'.join(row), axis=1)\n",
    "            formula = f'{response} ~ C({factor_cols[0]})*C({factor_cols[1]})'\n",
    "            model = ols(formula, data=df_sub).fit()\n",
    "            anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "            anova_table['P-value'] = anova_table['PR(>F)']\n",
    "            anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "            df_error = anova_table.loc['Residual', 'df'] if 'Residual' in anova_table.index else anova_table.iloc[-1]['df']\n",
    "            mse_error = anova_table.loc['Residual', 'sum_sq'] / anova_table.loc['Residual', 'df'] if 'Residual' in anova_table.index else anova_table.iloc[-1]['sum_sq'] / anova_table.iloc[-1]['df']\n",
    "            means = df_sub.groupby('group')[response].agg(['mean', 'count']).reset_index()\n",
    "            means.columns = ['group', 'Mean', 'n']\n",
    "            means = means.sort_values('Mean', ascending=False).reset_index(drop=True)\n",
    "            n_eff = means['n'].min()\n",
    "            alpha = 0.05\n",
    "            t_critical = t.ppf(1 - alpha/2, df_error)\n",
    "            lsd = t_critical * np.sqrt(2 * mse_error / n_eff)\n",
    "            letters_dict = get_lsd_letters_cld(means, lsd)\n",
    "            means['Letter'] = means['group'].map(letters_dict)\n",
    "            base = safe_sheet_name(response)\n",
    "            anova_table.to_excel(writer, sheet_name=f'{base}_ANOVA')\n",
    "            pd.DataFrame({'LSD_value': [lsd], 'alpha': [alpha], 't_critical': [t_critical], 'df_error': [df_error], 'mse_error': [mse_error]}).to_excel(writer, sheet_name=f'{base}_LSD', index=False)\n",
    "            means.to_excel(writer, sheet_name=f'{base}_Means', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30509f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(2)\n",
    "# df_threeway = pd.DataFrame({\n",
    "#     'f1': np.repeat(['P', 'Q'], 12),\n",
    "#     'f2': np.tile(np.repeat(['R', 'S'], 6), 2),\n",
    "#     'f3': np.tile(['U', 'V', 'U', 'V', 'U', 'V'], 4),\n",
    "#     'response': np.random.normal(loc=30, scale=4, size=24)\n",
    "# })\n",
    "# df_threeway.to_excel(\"dummy_threeway.xlsx\", index=False)\n",
    "# df_threeway.head()\n",
    "df_threeway = pd.read_excel(\"C:\\\\Users\\\\mirza\\\\OneDrive\\\\Desktop\\\\Copy of Mungbean_Excel_sheet(1).xlsx\", sheet_name=\"Sheet3\")\n",
    "df_threeway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three Way ANOVA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import t\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import re\n",
    "\n",
    "# Load your data\n",
    "file_path = \"C:\\\\Users\\\\mirza\\\\OneDrive\\\\Desktop\\\\Copy of Mungbean_Excel_sheet(1).xlsx\"\n",
    "sheet_name = \"Sheet3\"\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Automatically get factor and response columns\n",
    "factor_cols = df.columns[:3].tolist()\n",
    "response_cols = df.columns[3:].tolist()\n",
    "\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "def get_lsd_letters_cld(means_sorted, lsd):\n",
    "    group_names = means_sorted['group'].tolist()\n",
    "    means = means_sorted['Mean'].values\n",
    "    n = len(means)\n",
    "    letter_sets = [set() for _ in range(n)]\n",
    "    current_letter = ord('a')\n",
    "    for i in range(n):\n",
    "        used_letters = set()\n",
    "        for j in range(i):\n",
    "            if abs(means[i] - means[j]) > lsd:\n",
    "                used_letters |= letter_sets[j]\n",
    "        while chr(current_letter) in used_letters:\n",
    "            current_letter += 1\n",
    "        letter_sets[i].add(chr(current_letter))\n",
    "        for j in range(i+1, n):\n",
    "            if abs(means[i] - means[j]) <= lsd:\n",
    "                letter_sets[j].add(chr(current_letter))\n",
    "    letters = [''.join(sorted(s)) for s in letter_sets]\n",
    "    return dict(zip(group_names, letters))\n",
    "\n",
    "def safe_sheet_name(name, suffix=\"\"):\n",
    "    # Remove invalid characters and truncate to 25 chars (to allow suffix)\n",
    "    name = re.sub(r'[\\\\/*?:\\[\\]]', '_', str(name))\n",
    "    base = name[:25]\n",
    "    return f\"{base}{suffix}\"\n",
    "\n",
    "with pd.ExcelWriter('all_responses_anova_results.xlsx') as writer:\n",
    "    for idx, response in enumerate(response_cols):\n",
    "        # Drop NA for this response\n",
    "        df_sub = df[factor_cols + [response]].dropna()\n",
    "        # Create group label\n",
    "        df_sub['group'] = df_sub[factor_cols].astype(str).apply(lambda row: '_'.join(row), axis=1)\n",
    "        # ANOVA\n",
    "        formula = f'{response} ~ C({factor_cols[0]})*C({factor_cols[1]})*C({factor_cols[2]})'\n",
    "        model = ols(formula, data=df_sub).fit()\n",
    "        anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "        anova_table['P-value'] = anova_table['PR(>F)']\n",
    "        anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "        # Degrees of freedom and MSE\n",
    "        df_error = anova_table.loc['Residual', 'df'] if 'Residual' in anova_table.index else anova_table.iloc[-1]['df']\n",
    "        mse_error = anova_table.loc['Residual', 'sum_sq'] / anova_table.loc['Residual', 'df'] if 'Residual' in anova_table.index else anova_table.iloc[-1]['sum_sq'] / anova_table.iloc[-1]['df']\n",
    "        # LSD\n",
    "        means_3way = df_sub.groupby('group')[response].agg(['mean', 'count']).reset_index()\n",
    "        means_3way.columns = ['group', 'Mean', 'n']\n",
    "        means_3way['Original_Index'] = means_3way.index\n",
    "        means_3way = means_3way.sort_values('Mean', ascending=False).reset_index(drop=True)\n",
    "        n_eff = means_3way['n'].min()\n",
    "        alpha = 0.05\n",
    "        t_critical = t.ppf(1 - alpha/2, df_error)\n",
    "        lsd = t_critical * np.sqrt(2 * mse_error / n_eff)\n",
    "        # LSD letters\n",
    "        letters_dict_3way = get_lsd_letters_cld(means_3way, lsd)\n",
    "        means_3way['Letter'] = means_3way['group'].map(letters_dict_3way)\n",
    "        # Safe sheet names\n",
    "        base = safe_sheet_name(response)\n",
    "        anova_table.to_excel(writer, sheet_name=f'{base}_ANOVA')\n",
    "        pd.DataFrame({'LSD_value': [lsd], 'alpha': [alpha], 't_critical': [t_critical], 'df_error': [df_error], 'mse_error': [mse_error]}).to_excel(writer, sheet_name=f'{base}_LSD', index=False)\n",
    "        means_3way.to_excel(writer, sheet_name=f'{base}_Means', index=False)\n",
    "print(\"Exported all ANOVA, LSD, and mean comparison results for all responses.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec68a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukhys HSD\n",
    "\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Combine all factor columns into a single group label for interaction means\n",
    "df_threeway['group'] = (\n",
    "    df_threeway['Treatment'].astype(str) + \"_\" +\n",
    "    df_threeway['Cultivar'].astype(str) + \"_\" +\n",
    "    df_threeway['Stress'].astype(str)\n",
    ")\n",
    "\n",
    "# Calculate means for each interaction group\n",
    "means_3way = df_threeway.groupby('group')['RL'].mean().reset_index()\n",
    "means_3way.columns = ['group', 'Mean']\n",
    "\n",
    "# Sort means descending so highest mean gets 'A'\n",
    "means_3way = means_3way.sort_values('Mean', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Tukey HSD test on the interaction groups\n",
    "mc_3way = MultiComparison(df_threeway['RL'], df_threeway['group'])\n",
    "tukey_result_3way = mc_3way.tukeyhsd()\n",
    "\n",
    "# Assign significance letters, starting from highest mean\n",
    "import numpy as np\n",
    "\n",
    "def get_significance_letters_highest_first(tukey_result, means_sorted):\n",
    "    group_names = means_sorted['group'].tolist()\n",
    "    n = len(group_names)\n",
    "    sig_matrix = np.ones((n, n), dtype=bool)\n",
    "    summary = tukey_result.summary()\n",
    "    data = summary.data[1:]  # skip header\n",
    "    group_to_idx = {name: i for i, name in enumerate(group_names)}\n",
    "    for row in data:\n",
    "        g1, g2, _, _, _, _, reject = row\n",
    "        if g1 in group_to_idx and g2 in group_to_idx:\n",
    "            i, j = group_to_idx[g1], group_to_idx[g2]\n",
    "            sig_matrix[i, j] = not reject\n",
    "            sig_matrix[j, i] = not reject\n",
    "    letters = [''] * n\n",
    "    current_letter = 'A'\n",
    "    assigned = [False] * n\n",
    "    for i in range(n):\n",
    "        if not assigned[i]:\n",
    "            letters[i] += current_letter\n",
    "            assigned[i] = True\n",
    "            for j in range(i+1, n):\n",
    "                if sig_matrix[i, j]:\n",
    "                    letters[j] += current_letter\n",
    "                    assigned[j] = True\n",
    "            current_letter = chr(ord(current_letter) + 1)\n",
    "    return dict(zip(group_names, letters))\n",
    "\n",
    "letters_dict_3way = get_significance_letters_highest_first(tukey_result_3way, means_3way)\n",
    "means_3way['Letter'] = means_3way['group'].map(letters_dict_3way)\n",
    "\n",
    "print(means_3way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSD Value Calculation for Three-way ANOVA for single letters\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "# Combine all factor columns into a single group label for interaction means\n",
    "df_threeway['group'] = (\n",
    "    df_threeway['Treatment'].astype(str) + \"_\" +\n",
    "    df_threeway['Cultivar'].astype(str) + \"_\" +\n",
    "    df_threeway['Stress'].astype(str)\n",
    ")\n",
    "\n",
    "# Calculate means for each interaction group\n",
    "means_3way = df_threeway.groupby('group')['RL'].mean().reset_index()\n",
    "means_3way.columns = ['group', 'Mean']\n",
    "\n",
    "# Sort means descending so highest mean gets 'A'\n",
    "means_3way = means_3way.sort_values('Mean', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Calculate LSD value\n",
    "# You must have already calculated mse_error and df_error from your ANOVA table\n",
    "# n = number of replicates per group (adjust as needed)\n",
    "n = 3\n",
    "alpha = 0.05\n",
    "t_critical = t.ppf(1 - alpha/2, df_error)\n",
    "lsd = t_critical * np.sqrt(2 * mse_error / n)\n",
    "\n",
    "# Assign significance letters using LSD\n",
    "def get_lsd_letters(means_sorted, lsd):\n",
    "    group_names = means_sorted['group'].tolist()\n",
    "    means = means_sorted['Mean'].values\n",
    "    n = len(means)\n",
    "    sig_matrix = np.ones((n, n), dtype=bool)\n",
    "    # Compare all pairs\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if abs(means[i] - means[j]) > lsd:\n",
    "                sig_matrix[i, j] = False\n",
    "                sig_matrix[j, i] = False\n",
    "    # Assign letters\n",
    "    letters = [''] * n\n",
    "    current_letter = 'A'\n",
    "    assigned = [False] * n\n",
    "    for i in range(n):\n",
    "        if not assigned[i]:\n",
    "            letters[i] += current_letter\n",
    "            assigned[i] = True\n",
    "            for j in range(i+1, n):\n",
    "                if sig_matrix[i, j]:\n",
    "                    letters[j] += current_letter\n",
    "                    assigned[j] = True\n",
    "            current_letter = chr(ord(current_letter) + 1)\n",
    "    return dict(zip(group_names, letters))\n",
    "\n",
    "letters_dict_3way = get_lsd_letters(means_3way, lsd)\n",
    "means_3way['Letter'] = means_3way['group'].map(letters_dict_3way)\n",
    "\n",
    "print(means_3way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec118d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "df_fourway = pd.DataFrame({\n",
    "    'f1': np.repeat(['A', 'B'], 16),\n",
    "    'f2': np.tile(np.repeat(['C', 'D'], 8), 2),\n",
    "    'f3': np.tile(['E', 'F'], 16),\n",
    "    'f4': np.tile(['G', 'H', 'G', 'H'], 8),\n",
    "    'response': np.random.normal(loc=40, scale=5, size=32)\n",
    "})\n",
    "df_fourway.to_excel(\"dummy_fourway.xlsx\", index=False)\n",
    "df_fourway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88685eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy 4-way ANOVA data saved as 'dummy_4way_anova_data.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "def generate_dummy_4way_data():\n",
    "    # Factor levels\n",
    "    levels_A = ['A1', 'A2']\n",
    "    levels_B = ['B1', 'B2']\n",
    "    levels_C = ['C1', 'C2', 'C3']\n",
    "    levels_D = ['D1', 'D2']\n",
    "\n",
    "    # Number of replicates per combination\n",
    "    replicates = 3\n",
    "\n",
    "    # Create all combinations of factor levels\n",
    "    combinations = list(product(levels_A, levels_B, levels_C, levels_D))\n",
    "    data = []\n",
    "\n",
    "    np.random.seed(42)  # Reproducibility\n",
    "\n",
    "    for a, b, c, d in combinations:\n",
    "        # Base effect per factor\n",
    "        base = 10\n",
    "        a_effect = 5 if a == 'A2' else 0\n",
    "        b_effect = 3 if b == 'B2' else 0\n",
    "        c_effect = {'C1': 0, 'C2': 4, 'C3': -2}[c]\n",
    "        d_effect = 2 if d == 'D2' else 0\n",
    "\n",
    "        # Simulate interaction and random noise\n",
    "        interaction_effect = (a_effect + b_effect) * (c_effect + d_effect) * 0.1\n",
    "        for _ in range(replicates):\n",
    "            noise = np.random.normal(0, 1.5)\n",
    "            response = base + a_effect + b_effect + c_effect + d_effect + interaction_effect + noise\n",
    "            data.append([a, b, c, d, response])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Factor_A', 'Factor_B', 'Factor_C', 'Factor_D', 'Response'])\n",
    "    return df\n",
    "\n",
    "# Generate and save\n",
    "df_4way = generate_dummy_4way_data()\n",
    "df_4way.to_excel(\"dummy_4way_anova_data.xlsx\", index=False)\n",
    "print(\"Dummy 4-way ANOVA data saved as 'dummy_4way_anova_data.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four-way ANOVA\n",
    "model = ols('response ~ C(f1)*C(f2)*C(f3)*C(f4)', data=df_fourway).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0cec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "df_crd = pd.DataFrame({\n",
    "    'treatment': np.repeat(['T1', 'T2', 'T3', 'T4'], 8),\n",
    "    'response': np.random.normal(loc=15, scale=2, size=32)\n",
    "})\n",
    "df_crd.to_excel(\"dummy_crd.xlsx\", index=False)\n",
    "df_crd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fe9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRD (Completely Randomized Design)\n",
    "# Same as one-way ANOVA, just use your treatment column\n",
    "model = ols('response ~ C(treatment)', data=df_crd).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "df_rcbd = pd.DataFrame({\n",
    "    'treatment': np.tile(['T1', 'T2', 'T3', 'T4'], 5),\n",
    "    'block': np.repeat(['B1', 'B2', 'B3', 'B4', 'B5'], 4),\n",
    "    'response': np.random.normal(loc=18, scale=2, size=20)\n",
    "})\n",
    "df_rcbd.to_excel(\"dummy_rcbd.xlsx\", index=False)\n",
    "df_rcbd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d8c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RCBD (Randomized Complete Block Design)\n",
    "model = ols('response ~ C(treatment) + C(block)', data=df_rcbd).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92be944",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6)\n",
    "df_splitplot = pd.DataFrame({\n",
    "    'mainplot': np.repeat(['M1', 'M2'], 12),\n",
    "    'subplot': np.tile(np.repeat(['S1', 'S2'], 3), 4),\n",
    "    'response': np.random.normal(loc=22, scale=3, size=24)\n",
    "})\n",
    "df_splitplot.to_excel(\"dummy_splitplot.xlsx\", index=False)\n",
    "df_splitplot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971f72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-plot (basic)\n",
    "model = ols('response ~ C(mainplot) * C(subplot)', data=df_splitplot).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4356c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "df_splitsplit = pd.DataFrame({\n",
    "    'mainplot': np.repeat(['M1', 'M2'], 8),\n",
    "    'subplot': np.tile(np.repeat(['S1', 'S2'], 2), 4),\n",
    "    'subsubplot': np.tile(['SS1', 'SS2'], 8),\n",
    "    'response': np.random.normal(loc=25, scale=3, size=16)\n",
    "})\n",
    "df_splitsplit.to_excel(\"dummy_splitsplit.xlsx\", index=False)\n",
    "df_splitsplit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e23d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-split plot (basic)\n",
    "model = ols('response ~ C(mainplot) * C(subplot) * C(subsubplot)', data=df_splitsplit).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfcca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(8)\n",
    "df_latin = pd.DataFrame({\n",
    "    'row': np.tile(['R1', 'R2', 'R3', 'R4'], 4),\n",
    "    'column': np.repeat(['C1', 'C2', 'C3', 'C4'], 4),\n",
    "    'treatment': np.tile(['T1', 'T2', 'T3', 'T4'], 4),\n",
    "    'response': np.random.normal(loc=28, scale=2, size=16)\n",
    "})\n",
    "df_latin.to_excel(\"dummy_latin_square.xlsx\", index=False)\n",
    "df_latin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ccf805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latin Square\n",
    "model = ols('response ~ C(row) + C(column) + C(treatment)', data=df_latin).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd30ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(9)\n",
    "df_splitblock = pd.DataFrame({\n",
    "    'block1': np.repeat(['B1', 'B2'], 8),\n",
    "    'block2': np.tile(['B3', 'B4'], 8),\n",
    "    'treatment': np.tile(['T1', 'T2'], 8),\n",
    "    'response': np.random.normal(loc=32, scale=2, size=16)\n",
    "})\n",
    "df_splitblock.to_excel(\"dummy_splitblock.xlsx\", index=False)\n",
    "df_splitblock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53416b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split block (basic)\n",
    "model = ols('response ~ C(block1) + C(block2) + C(treatment)', data=df_splitblock).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c83a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "df_stripsplit = pd.DataFrame({\n",
    "    'strip1': np.repeat(['S1', 'S2'], 8),\n",
    "    'strip2': np.tile(['S3', 'S4'], 8),\n",
    "    'subplot': np.tile(['SP1', 'SP2'], 8),\n",
    "    'response': np.random.normal(loc=35, scale=2, size=16)\n",
    "})\n",
    "df_stripsplit.to_excel(\"dummy_stripsplit.xlsx\", index=False)\n",
    "df_stripsplit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3516a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip-split (basic)\n",
    "model = ols('response ~ C(strip1) * C(strip2) * C(subplot)', data=df_stripsplit).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)\n",
    "df_splsqr = pd.DataFrame({\n",
    "    'row': np.tile(['R1', 'R2', 'R3'], 6),\n",
    "    'column': np.repeat(['C1', 'C2', 'C3'], 6),\n",
    "    'mainplot': np.tile(['M1', 'M2'], 9),\n",
    "    'subplot': np.tile(['S1', 'S2', 'S3'], 6),\n",
    "    'response': np.random.normal(loc=38, scale=2, size=18)\n",
    "})\n",
    "df_splsqr.to_excel(\"dummy_splitplot_latin_square.xlsx\", index=False)\n",
    "df_splsqr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc81dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-plot Latin Square (basic)\n",
    "model = ols('response ~ C(row) + C(column) + C(mainplot) * C(subplot)', data=df_splsqr).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "def significance_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    elif p < 0.1:\n",
    "        return '.'\n",
    "    else:\n",
    "        return 'ns'\n",
    "\n",
    "anova_table['P-value'] = anova_table['PR(>F)']\n",
    "anova_table['Signif.'] = anova_table['PR(>F)'].apply(significance_stars)\n",
    "display(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f03c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export ANOVA table to text\n",
    "anova_table.to_csv(\"anova_table.txt\", sep=\"\\t\")\n",
    "\n",
    "# Export to docx\n",
    "from docx import Document\n",
    "doc = Document()\n",
    "doc.add_heading('ANOVA Table', 0)\n",
    "t = doc.add_table(rows=1, cols=len(anova_table.columns)+1)\n",
    "hdr_cells = t.rows[0].cells\n",
    "hdr_cells[0].text = 'Source'\n",
    "for i, col in enumerate(anova_table.columns):\n",
    "    hdr_cells[i+1].text = col\n",
    "for idx, row in anova_table.iterrows():\n",
    "    row_cells = t.add_row().cells\n",
    "    row_cells[0].text = str(idx)\n",
    "    for i, val in enumerate(row):\n",
    "        row_cells[i+1].text = str(val)\n",
    "doc.save(\"anova_table.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to PDF\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "fig, ax = plt.subplots(figsize=(8,2))\n",
    "ax.axis('off')\n",
    "tbl = ax.table(cellText=anova_table.values, colLabels=anova_table.columns, rowLabels=anova_table.index, loc='center')\n",
    "plt.tight_layout()\n",
    "pdf = PdfPages(\"anova_table.pdf\")\n",
    "pdf.savefig(fig)\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1216ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to XML\n",
    "import xml.etree.ElementTree as ET\n",
    "root = ET.Element(\"ANOVATable\")\n",
    "for idx, row in anova_table.iterrows():\n",
    "    entry = ET.SubElement(root, \"Row\", source=str(idx))\n",
    "    for col, val in row.items():\n",
    "        ET.SubElement(entry, col).text = str(val)\n",
    "tree = ET.ElementTree(root)\n",
    "tree.write(\"anova_table.xml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
